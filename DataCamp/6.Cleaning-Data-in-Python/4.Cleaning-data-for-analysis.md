&copy; Copyright for Shuang Wu 2017<br>
Cite from the DataCamp website<br>
**Do not cite this notebook in any situation**<br>
Persenoal reference only, **do not copy** the code or others
- [Data types](#data-types)
    - [Converting data types](#converting-data-types)
    - [Working w/ numeric data](#working-w-numeric-data)
- [Using regular expressions to clean strings](#using-regular-expressions-to-clean-strings)
    - [String parsing w/ regular expressions](#string-parsing-w-regular-expressions)
    - [Extracting numerical values from strings](#extracting-numerical-values-from-strings)
    - [Pattern matching](#pattern-matching)
- [Using functions to clean data](#using-functions-to-clean-data)
    - [Custom functions to clean data](#custom-functions-to-clean-data)
    - [Lambda functions](#lambda-functions)
- [Duplicate and missing data](#duplicate-and-missing-data)
- [Testing w/ asserts](#testing-w-asserts)


# Data types

* Prepare and clean data
* Data types
    * object
    * int64
    * There may be times we want to aconver from one type to another
        * numeric col may be string
* Converting data types
* Categorical data
    * converting categorical data to 'category' dtype:
        * can make the DF smaller in memory
        * Can make them be utilized by other python libraries for analysis
* Cleaning data
    * numeric data loaded as string

## Converting data types

* Ensuring all categorical variables in a DFs are of type _category_ reduces memory usage

```python {.input}
tips.sex = tips.sex.astype('category')
tips.smoker = tips.smoker.astype('category')
print(tips.info())
```
Output:<br>
<class 'pandas.core.frame.DataFrame'><br>
RangeIndex: 244 entries, 0 to 243<br>
Data columns (total 7 columns):<br>
total_bill    244 non-null float64<br>
tip           244 non-null float64<br>
sex           244 non-null object<br>
smoker        244 non-null object<br>
day           244 non-null object<br>
time          244 non-null object<br>
size          244 non-null int64<br>
dtypes: float64(2), int64(1), object(4)<br>
memory usage: 13.4+ KB<br>

## Working w/ numeric data

* If expect the data type of a col. to be numeric (_int_ or _float_), but instead it is of type _object_, this typically means that there is a non numeric value in the col., which also signifies bad data
* Use _pd.to_numeric()_ function to conver a col. into a numeric data type
    * if func. raises an error, can be sure that there is a bad value w/in the col
    * can either do some exploratory data analysis and find the bad value
    * or choose to ignore or _coerce_ the value into a missing val. _NaN_

```python {.input}
tips['total_bill'] = pd.to_numeric(tips['total_bill'], errors='coerce')
tips['tip'] = pd.to_numeric(tips['tip'], errors='coerce')
print(tips.info())
```
Output:<br>
    <class 'pandas.core.frame.DataFrame'><br>
    RangeIndex: 244 entries, 0 to 243<br>
    Data columns (total 7 columns):<br>
    total_bill    202 non-null float64<br>
    tip           220 non-null float64<br>
    sex           234 non-null category<br>
    smoker        229 non-null category<br>
    day           243 non-null category<br>
    time          227 non-null category<br>
    size          231 non-null float64<br>
    dtypes: category(4), float64(3)<br>
    memory usage: 6.9 KB<br>
    None<br>

# Using regular expressions to clean strings

* String manipulation
    * Much of data cleaning involves string manipulation
        * most of the world's data is unstructured test
    * Also have to do string manipulation to make datasets consistent w/ one another
* Validate values
    * 17
        * \d*
    * $17
        * \$\d*
    * $17.00
        * \$\d*\.\d*
    * $17.89
        * \$\d*\.\d{2}
    * $17.895
        * ^\$\d*\.\d{2}$
* String manipulation
    * Many built-in and external libraries
    * 're' library for regular expressions
        * A formal way of specifying a pattern
        * Sequence of characters
* Pattern matching
    * similar to globbing
* Using regular expressions
    * compile the pattern
    * use the compiled pattern to match values
    * This lets us use the pattern over and over again
    * Useful since we want to match values down a col. of values

## String parsing w/ regular expressions

* When working w/ data, it's sth necessary to write a regular expression to look for properly entered vals.
* The regular expression module in python is _re_
* When performing pattern matching on data, since the pattern will be used for a match across multiple rows, it's better to compile the pattern first using _re.compile()_, and then use the compiled pattern to match values

```python {.input}
import re
prog = re.compile('\d{3}-\d{3}-\d{4}')
result = prog.match('123-456-7890')
print(bool(result))
result = prog.match('1123-456-7890')
print(bool(result))
```
Output:<br>
True<br>
False<br>

## Extracting numerical values from strings

* Extracting numbers from strings is a common task, paticularly when working w/ unstructured data or log files
* regular expression to extract multiple numbers (or multiple pattern matches, to be exact) is use the _re.findall()_ func
* Its straightforward to use: pass in a pattern and a string to _re.findall()_ and it will return a list of the mathces

```python {.input}
import re
matches = re.findall('\d+', 'the recipe calls for 10 strawberries and 1 banana')
print(matches)
```
Output:<br>
['10', '1']<br>

## Pattern matching

* Regular expression

```python {.input}
pattern1 = bool(re.match(pattern='\d{3}-\d{3}-\d{3}', string='123-456-7890'))
print(pattern1)
pattern2 = bool(re.match(pattern='\$\d*\.\d{2}', string='$123.45'))
print(pattern2)
pattern3 = bool(re.match(pattern='A\w*', string='Australia'))
print(pattern3)
```
Output:<br>
True<br>
True<br>
True<br>

# Using functions to clean data

* Complex cleaning
    * Cleaning step requires multiple steps
        * Extract number from string
        * perform transformation on extracted number
    * Python function
* Applying functions
* Write the regular expression
* writing a function

## Custom functions to clean data

* Recoding variables is a common data cleaning task
* Functions provide a mechanism to abstract waay complex bits of code as well as reuse code
* This makes code more readable and less error prone
* Can use _.apply()_ method to apply a function across entire rows or columns of DFs. However, each col. of DF is a pandas Series
* Functions can also be applied across Series

```python {.input}
def recode_sex(sex_value):
    if sex_value == 'Male':
        return 1
    elif sex_value == 'Female':
        return 0  
    else:
        return np.nan
tips['sex_recode'] = tips.sex.apply(recode_sex)
print(tips.head())
```
Output:<br>

Index | total_bill | tip | sex | smoker | day | time | size | sex_recode
------|------------|-----|-----|--------|-----|------|------|-----------
0 | 16.99 | 1.01 | Female | No | Sun | Dinner | 2.0 | 0.0
1 | 10.34 | 1.66 | Male | No | Sun | Dinner | 3.0 | 1.0
2 | NaN | 3.50 | Male | No | Sun | Dinner | 3.0 | 1.0
3 | 23.68 | 3.31 | Male | No | Sun | Dinner | 2.0 | 1.0
4 | 24.59 | 3.61 | Female | No | Sun | NaN | 4.0 | 0.0

## Lambda functions

* A powerful python feature that help clean data more effectively: lambda functions
* Instead of using _def_ syntax that used in the previous exercise, lamda functions make simple, one-line functions
* E.g., a function that squares a variable used in an _.apply()_ method:
```python {.example}
def my_square(x):
    return x ** 2
df.apply(my_square)
```
* The equivalent code using a lambda func is:
```python {.example}
df.apply(lambda x: x ** 2)
```
* The lambda func. takes one parameter - the variable _x_.
* The function itself just squares _x_ and returns the result, which is whatever the one line of code evaluates to
* In this way, lambda func. can make code concise and Pythonic

```python {.input}
tips['total_dollar_replace'] = tips.total_dollar.apply(lambda x: x.replace('$', ''))
tips['total_dollar_re'] = tips.total_dollar.apply(lambda x: re.findall('\d+\.\d+', x)[0])
print(tips.head())
```
Output:<br>

Index | total_bill | tip | sex | smoker | day | time | size total_dollar | total_dollar_replace | total_dollar_re | 
------|------------|-----|-----|--------|-----|------|-------------------|----------------------|----------------
0 | 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | $16.99 | 16.99 | 16.99 
1 | 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | $10.34 | 10.34 | 10.34 
2 | 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | $21.01 | 21.01 | 21.01 
3 | 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | $23.68 | 23.68 | 23.68 
4 | 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | $24.59 | 24.59 | 24.59




# Duplicate and missing data


# Testing w/ asserts